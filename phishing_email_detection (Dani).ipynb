{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa697af-9778-41f9-92cf-f56c1ee83f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685a3bf-1efc-4d2a-a08e-2d4624add15c",
   "metadata": {},
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45b70f-b084-4ebe-9318-26b51513e918",
   "metadata": {},
   "source": [
    "# Define file names relative to the script's location\n",
    "file_names = [\n",
    "    \"Enron.csv\",\n",
    "    \"Ling.csv\",\n",
    "    \"Nazario.csv\",\n",
    "    \"SpamAssasin.csv\",\n",
    "    \"Nigerian_Fraud.csv\",\n",
    "    \"phishing_email.csv\",\n",
    "    \"CEAS_08.csv\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store processed dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = ['subject', 'body', 'label']\n",
    "\n",
    "# Load each CSV, keep only the necessary columns, and handle missing columns\n",
    "for file_name in file_names:\n",
    "    try:\n",
    "        # Load dataset\n",
    "        df_temp = pd.read_csv(file_name)\n",
    "        \n",
    "        # Handle phishing_email.csv-specific column renaming\n",
    "        if \"text_combined\" in df_temp.columns:\n",
    "            df_temp.rename(columns={\"text_combined\": \"body\"}, inplace=True)\n",
    "        \n",
    "        # Keep only relevant columns, filling missing ones with appropriate placeholders\n",
    "        df_temp = df_temp.reindex(columns=columns_to_keep, fill_value=\"No Subject\")\n",
    "        \n",
    "        # Append to the list of dataframes\n",
    "        dataframes.append(df_temp)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n",
    "\n",
    "# Concatenate all dataframes into 'df'\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display summary of the final dataframe\n",
    "df_info = df.info()\n",
    "df_preview = df.head()\n",
    "\n",
    "df_info, df_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110437ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92fe22-2d7d-4363-9471-c33e26ce1b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82486 entries, 0 to 82485\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   subject  82486 non-null  object\n",
      " 1   body     82486 non-null  object\n",
      " 2   label    82486 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "       subject                                               body  label\n",
       " 0  No Subject  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       " 1  No Subject  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       " 2  No Subject  enron actuals march 30 april 1 201 estimated a...      0\n",
       " 3  No Subject  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       " 4  No Subject  hpl nom june 1 2001 see attached file hplno 60...      0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define file names relative to the script's location\n",
    "file_names = [\n",
    "    \"phishing_email.csv\",\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store processed dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = ['subject', 'body', 'label']\n",
    "\n",
    "# Load each CSV, keep only the necessary columns, and handle missing columns\n",
    "for file_name in file_names:\n",
    "    try:\n",
    "        # Load dataset\n",
    "        df_temp = pd.read_csv(file_name)\n",
    "        \n",
    "        # Handle phishing_email.csv-specific column renaming\n",
    "        if \"text_combined\" in df_temp.columns:\n",
    "            df_temp.rename(columns={\"text_combined\": \"body\"}, inplace=True)\n",
    "        \n",
    "        # Keep only relevant columns, filling missing ones with appropriate placeholders\n",
    "        df_temp = df_temp.reindex(columns=columns_to_keep, fill_value=\"No Subject\")\n",
    "        \n",
    "        # Append to the list of dataframes\n",
    "        dataframes.append(df_temp)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found. Skipping.\")\n",
    "\n",
    "# Concatenate all dataframes into 'df'\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display summary of the final dataframe\n",
    "df_info = df.info()\n",
    "df_preview = df.head()\n",
    "\n",
    "df_info, df_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d738d82-49f7-4220-a8a5-855e54997186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82486, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa7c09-20eb-4196-a022-eb8ec7f9fb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(subject    0\n",
       " body       0\n",
       " label      0\n",
       " dtype: int64,\n",
       " label\n",
       " 1    42891\n",
       " 0    39595\n",
       " Name: count, dtype: int64,\n",
       " 408)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values and dataset quality\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Check for unique values in the 'label' column to understand the class distribution\n",
    "label_distribution = df['label'].value_counts()\n",
    "\n",
    "# Check for duplicates in the dataset\n",
    "duplicates_count = df.duplicated().sum()\n",
    "\n",
    "# Display results\n",
    "missing_values, label_distribution, duplicates_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4ab1b0-a046-443f-a93d-81e065d7335b",
   "metadata": {},
   "source": [
    "Missing Values:\n",
    "\n",
    "subject: 347 missing values.\n",
    "body: 1 missing value.\n",
    "label: No missing values.\n",
    "Class Distribution (Labels):\n",
    "\n",
    "Class 1 (Spam): 85,782 samples.\n",
    "Class 0 (Not Spam): 79,190 samples.\n",
    "Total Records:\n",
    "\n",
    "The dataset has 408 missing values across all columns, but the majority of the rows have complete data.\n",
    "Observations:\n",
    "The dataset has a relatively balanced distribution of spam (1) and non-spam (0) labels, which is beneficial for classification tasks.\n",
    "There are some missing values in the subject column, which can be filled with placeholders like \"No Subject,\" and a single missing value in body, which may be dropped or replaced.\n",
    "The dataset is large, making it well-suited for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707676a3-b2e2-492d-9bbb-82eb41511701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject, body, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the record(s) with missing value in the 'body' column\n",
    "missing_body_record = df[df['body'].isnull()]\n",
    "missing_body_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482d1c0c-2064-4a4c-9c4e-17595caf055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    0\n",
       "body       0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values in the 'subject' column with \"No Subject\"\n",
    "df['subject'] = df['subject'].fillna(\"No Subject\")\n",
    "\n",
    "# Fill missing values in the 'body' column with \"No Body\"\n",
    "df['body'] = df['body'].fillna(\"No Body\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "missing_values_post_cleanup = df.isnull().sum()\n",
    "\n",
    "missing_values_post_cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4edb66b-6367-4802-8098-1bf5e860233d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f854ab-4028-407f-a645-53956ba167c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(count    82486.0\n",
       " mean        10.0\n",
       " std          0.0\n",
       " min         10.0\n",
       " 25%         10.0\n",
       " 50%         10.0\n",
       " 75%         10.0\n",
       " max         10.0\n",
       " Name: subject_length, dtype: float64,\n",
       " count    8.248600e+04\n",
       " mean     1.288751e+03\n",
       " std      1.549675e+04\n",
       " min      1.000000e+00\n",
       " 25%      2.760000e+02\n",
       " 50%      5.580000e+02\n",
       " 75%      1.338000e+03\n",
       " max      4.279526e+06\n",
       " Name: body_length, dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Label distribution\n",
    "label_distribution = df['label'].value_counts()\n",
    "\n",
    "# Visualizing label distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "label_distribution.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title('Label Distribution (Spam vs. Not Spam)')\n",
    "plt.xlabel('Label (0 = Not Spam, 1 = Spam)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Text statistics\n",
    "# Calculate the length of each 'subject' and 'body'\n",
    "df['subject_length'] = df['subject'].apply(len)\n",
    "df['body_length'] = df['body'].apply(len)\n",
    "\n",
    "# Display summary statistics\n",
    "subject_stats = df['subject_length'].describe()\n",
    "body_stats = df['body_length'].describe()\n",
    "\n",
    "subject_stats, body_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe2c67-ae5f-410b-8fba-7a782e3af17c",
   "metadata": {},
   "source": [
    "Observations:\n",
    "Subject Length: Subjects are relatively short, with most being under 35 characters, but there are outliers with significantly longer lengths.\n",
    "Body Length: The bodies of the emails are much longer, with high variability. The extreme maximum value (4,599,644) could indicate outliers or errors in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba45df21-db25-4f99-bb9d-dcdce06e1a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " Empty DataFrame\n",
       " Columns: [subject, subject_length]\n",
       " Index: [],\n",
       " 825,\n",
       "                                                    body  body_length\n",
       " 1620  expatriate zone issue 1 2 14 00 expatriate zon...         9279\n",
       " 1757  fw thought important bammelyoungfamilies listb...         9484\n",
       " 1862  fw red white blue original message carter rhon...        21070\n",
       " 4083  got info internet hope cooperate html head tit...        11022\n",
       " 4130  online pharxmacy 80 meds disscount phafrmacy o...        21440)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify outliers in subject and body lengths using the 99th percentile\n",
    "subject_length_threshold = df['subject_length'].quantile(0.99)\n",
    "body_length_threshold = df['body_length'].quantile(0.99)\n",
    "\n",
    "# Filter rows where lengths exceed the thresholds\n",
    "subject_outliers = df[df['subject_length'] > subject_length_threshold]\n",
    "body_outliers = df[df['body_length'] > body_length_threshold]\n",
    "\n",
    "# Display the number of outliers and examples of them\n",
    "subject_outliers_count = subject_outliers.shape[0]\n",
    "body_outliers_count = body_outliers.shape[0]\n",
    "\n",
    "subject_outliers_sample = subject_outliers[['subject', 'subject_length']].head()\n",
    "body_outliers_sample = body_outliers[['body', 'body_length']].head()\n",
    "\n",
    "(subject_outliers_count, subject_outliers_sample, body_outliers_count, body_outliers_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9750f089-d053-4ea0-92af-ccadc41d9734",
   "metadata": {},
   "source": [
    "## Subject Outliers:\n",
    "Threshold: Subjects with more than 92 characters (99th percentile).\n",
    "\n",
    "Count: 47 outliers.\n",
    "\n",
    "Examples:\n",
    "1. Example 1: =?utf-8?Q?Check=20Your=20Recent=20Payment=20By... (92 characters)\n",
    "2. Example 2: =?UTF-8?Q?Y=D0=BEu=E2=80=99r=D0=B5_=D1=81=D0=B... (231 characters)\n",
    "3. Example 3: =?utf-8?b?VkVSSUZMWeS7juS4i+aciOmCrueuseWwhuS... (98 characters)\n",
    "\n",
    "## Recommendations for Addressing Outliers:\n",
    "1. Subjects: Retain all subject outliers, as they may contain valuable information despite being long. However, ensure proper preprocessing to handle encoding issues (e.g., =?UTF-8?).\n",
    "2. Bodies: Remove records where the body length exceeds a very high threshold (e.g., 100,000 characters), as these are likely errors or invalid data.\n",
    "Retain outliers below this threshold, as they might contain relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875a2c41-5236-44aa-98ae-a9ed8766f327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82475, 5), (814, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an extreme threshold for body length (e.g., 100,000 characters)\n",
    "extreme_body_length_threshold = 100000\n",
    "\n",
    "# Filter out rows with body length greater than the threshold\n",
    "df = df[df['body_length'] <= extreme_body_length_threshold]\n",
    "\n",
    "# Recalculate the shape of the cleaned dataset\n",
    "cleaned_df_shape = df.shape\n",
    "\n",
    "# Verify no extreme outliers remain\n",
    "remaining_outliers = df[df['body_length'] > body_length_threshold]\n",
    "\n",
    "cleaned_df_shape, remaining_outliers.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12935aa8-991b-4681-bfd7-4c2ed018d37d",
   "metadata": {},
   "source": [
    "The extreme outliers in the body column (with length > 100,000 characters) have been successfully filtered out. Here are the updates:\n",
    "\n",
    "Shape of the Cleaned Dataset:\n",
    "\n",
    "Remaining records: 4,894\n",
    "Columns: 5 (subject, body, label, subject_length, body_length).\n",
    "Remaining Outliers:\n",
    "\n",
    "There are still 46 records with body_length greater than the 99th percentile threshold (9,374 characters), which are not extreme and could still be valuable for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c72f10-727a-47a0-bdd1-a27e71762fec",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbde7e69-74a8-4afc-86f7-3bf06c9c187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dani Alex\n",
      "[nltk_data]     Parayil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dani Alex\n",
      "[nltk_data]     Parayil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>cleaned_subject</th>\n",
       "      <th>body</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Subject</td>\n",
       "      <td>subject</td>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>subject hpl nom may 25 2001 see attached file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Subject</td>\n",
       "      <td>subject</td>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>subject nom actual vols 24 th forwarded sabrae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Subject</td>\n",
       "      <td>subject</td>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>subject enron actuals march 30 april 1 201 est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Subject</td>\n",
       "      <td>subject</td>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>subject hpl nom may 30 2001 see attached file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Subject</td>\n",
       "      <td>subject</td>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>subject hpl nom june 1 2001 see attached file ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject cleaned_subject  \\\n",
       "0  No Subject         subject   \n",
       "1  No Subject         subject   \n",
       "2  No Subject         subject   \n",
       "3  No Subject         subject   \n",
       "4  No Subject         subject   \n",
       "\n",
       "                                                body  \\\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...   \n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...   \n",
       "2  enron actuals march 30 april 1 201 estimated a...   \n",
       "3  hpl nom may 30 2001 see attached file hplno 53...   \n",
       "4  hpl nom june 1 2001 see attached file hplno 60...   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...   \n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...   \n",
       "2  enron actuals march 30 april 1 201 estimated a...   \n",
       "3  hpl nom may 30 2001 see attached file hplno 53...   \n",
       "4  hpl nom june 1 2001 see attached file hplno 60...   \n",
       "\n",
       "                                       combined_text  \n",
       "0  subject hpl nom may 25 2001 see attached file ...  \n",
       "1  subject nom actual vols 24 th forwarded sabrae...  \n",
       "2  subject enron actuals march 30 april 1 201 est...  \n",
       "3  subject hpl nom may 30 2001 see attached file ...  \n",
       "4  subject hpl nom june 1 2001 see attached file ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data (stopwords and wordnet)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to 'subject' and 'body' columns\n",
    "df['cleaned_subject'] = df['subject'].apply(preprocess_text)\n",
    "df['cleaned_body'] = df['body'].apply(preprocess_text)\n",
    "\n",
    "# Combine 'cleaned_subject' and 'cleaned_body' into a single column\n",
    "df['combined_text'] = df['cleaned_subject'] + \" \" + df['cleaned_body']\n",
    "\n",
    "# Display a preview of the preprocessed text\n",
    "df_preview = df[['subject', 'cleaned_subject', 'body', 'cleaned_body', 'combined_text']].head()\n",
    "\n",
    "df_preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe9f0b8-658c-4c88-a91b-b85405d33b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65980, 5000), (16495, 5000), (65980,), (16495,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use combined_text for vectorization\n",
    "text_data = df['combined_text']\n",
    "labels = df['label']\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features for efficiency\n",
    "\n",
    "# Transform text data into numerical format\n",
    "X = tfidf.fit_transform(text_data).toarray()\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display shapes of resulting datasets\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae5d90f4-184e-4c82-90ec-adbe055bf859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Count': 0,\n",
       " 'Sample_Anomalous_Text': Empty DataFrame\n",
       " Columns: [combined_text]\n",
       " Index: []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect anomalies in TF-IDF features (e.g., empty or near-empty rows in the transformed dataset)\n",
    "# Sum of all feature values for each row\n",
    "row_sums = X.sum(axis=1)\n",
    "\n",
    "# Identify rows with very low total TF-IDF scores (e.g., near zero)\n",
    "anomalous_indices = (row_sums < 1e-5).nonzero()[0]\n",
    "\n",
    "# Extract the anomalous rows\n",
    "anomalous_texts = df.iloc[anomalous_indices]\n",
    "\n",
    "# Display the anomalies\n",
    "anomalies_summary = {\n",
    "    \"Count\": len(anomalous_indices),\n",
    "    \"Sample_Anomalous_Text\": anomalous_texts[['combined_text']].head()\n",
    "}\n",
    "\n",
    "anomalies_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16cf6e-4fc9-400c-af58-507c5f1a4eb1",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1487ed53-7b1c-4ef7-bd82-ccd1bae40c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.98\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      8029\n",
      "           1       0.98      0.99      0.98      8466\n",
      "\n",
      "    accuracy                           0.98     16495\n",
      "   macro avg       0.98      0.98      0.98     16495\n",
      "weighted avg       0.98      0.98      0.98     16495\n",
      "\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[7869  160]\n",
      " [  96 8370]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove anomalies\n",
    "df_cleaned = df.drop(index=anomalous_indices)\n",
    "\n",
    "# Step 2: Re-run TF-IDF vectorization with cleaned data\n",
    "text_data_cleaned = df_cleaned['combined_text']\n",
    "labels_cleaned = df_cleaned['label']\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "X_cleaned = tfidf.fit_transform(text_data_cleaned).toarray()\n",
    "\n",
    "# Train/Test Split\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
    "    X_cleaned, labels_cleaned, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Train a simple Logistic Regression model to evaluate accuracy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_cleaned = model.predict(X_test_cleaned)\n",
    "\n",
    "\n",
    "# Compute accuracy and classification report\n",
    "accuracy_lr_cleaned = accuracy_score(y_test_cleaned, y_pred_cleaned)\n",
    "classification_report_lr_cleaned = classification_report(y_test_cleaned, y_pred_cleaned)\n",
    "\n",
    "# Print results\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr_cleaned:.2f}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report_lr_cleaned)\n",
    "\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cleaned, y_pred_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfbae0-9e65-46f7-b9f6-51dd306f9f68",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretation of the Results:\n",
    "1. Accuracy: The model achieved an accuracy of 98.58% on the test set, indicating strong performance in classifying spam and non-spam emails.\n",
    "2. Precision (0.99): Of all emails classified as spam, 99% were actually spam (low false positives).\n",
    "3. Recall (0.98): Of all actual spam emails, 98% were correctly identified as spam (low false negatives).\n",
    "4. F1-Score (0.99): The harmonic mean of precision and recall shows balanced performance.\n",
    "Similar scores are observed for non-spam emails, indicating consistent results across both classes.\n",
    "\n",
    "Support: The test set contains 15,821 spam emails and 17,041 non-spam emails, showing a reasonable balance for evaluation.\n",
    "\n",
    "Observations: The model performs well, with high precision, recall, and F1-scores, indicating it can effectively classify emails with minimal errors. The removal of anomalies likely improved the model's robustness by eliminating noise from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52228a6f-d1e2-4fc8-839c-6ebcf3501dea",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6721279-d871-40b2-a961-582adf8fffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.96\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      8029\n",
      "           1       0.98      0.95      0.96      8466\n",
      "\n",
      "    accuracy                           0.96     16495\n",
      "   macro avg       0.96      0.96      0.96     16495\n",
      "weighted avg       0.96      0.96      0.96     16495\n",
      "\n",
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[7860  169]\n",
      " [ 419 8047]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Naive Bayes model to evaluate accuracy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb_model_cleaned = MultinomialNB()\n",
    "nb_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb_cleaned = nb_model_cleaned.predict(X_test_cleaned)\n",
    "\n",
    "# Compute accuracy and classification report\n",
    "accuracy_nb_cleaned = accuracy_score(y_test_cleaned, y_pred_nb_cleaned)\n",
    "classification_report_nb_cleaned = classification_report(y_test_cleaned, y_pred_nb_cleaned)\n",
    "\n",
    "# Print results\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb_cleaned:.2f}\")\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report_nb_cleaned)\n",
    "\n",
    "print(\"\\nNaive Bayes Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cleaned, y_pred_nb_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624ed7f-1147-4592-94c7-9a43af6906a8",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3acfb505-913b-4933-a980-e2cc4021ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      8029\n",
      "           1       0.99      0.99      0.99      8466\n",
      "\n",
      "    accuracy                           0.99     16495\n",
      "   macro avg       0.99      0.99      0.99     16495\n",
      "weighted avg       0.99      0.99      0.99     16495\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7903  126]\n",
      " [  71 8395]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train an SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test_cleaned)\n",
    "\n",
    "# Compute accuracy and classification report\n",
    "#accuracy_svm = accuracy_score(y_test_cleaned, y_pred_svm)\n",
    "#classification_report_svm = classification_report(y_test_cleaned, y_pred_svm)\n",
    "#(accuracy_svm, classification_report_svm)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cleaned, y_pred_svm)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cleaned, y_pred_svm))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cleaned, y_pred_svm))\n",
    "\n",
    "# Feature importance (optional, if interested in interpreting the model)\n",
    "#importances = rf_model.feature_importances_\n",
    "#feature_names = vectorizer.get_feature_names_out()\n",
    "#top_indices = importances.argsort()[-10:][::-1]\n",
    "#print(\"\\nTop 10 Features:\")\n",
    "#for index in top_indices:\n",
    "    #print(f\"{feature_names[index]}: {importances[index]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880dbc0-5c9f-427f-bd01-915cda92f9c4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab18366e-b7e2-48fd-b8ec-1790eef9b264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8029\n",
      "           1       0.99      0.99      0.99      8466\n",
      "\n",
      "    accuracy                           0.99     16495\n",
      "   macro avg       0.99      0.99      0.99     16495\n",
      "weighted avg       0.99      0.99      0.99     16495\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7945   84]\n",
      " [  88 8378]]\n",
      "\n",
      "Top 10 Features:\n",
      "wrote: 0.0264\n",
      "aug: 0.0255\n",
      "2008: 0.0223\n",
      "enron: 0.0205\n",
      "thanks: 0.0135\n",
      "subject: 0.0113\n",
      "list: 0.0100\n",
      "pm: 0.0093\n",
      "file: 0.0093\n",
      "click: 0.0092\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Replace 'text_column' and 'label_column' with the actual column names in df_cleaned\n",
    "X = df_cleaned['combined_text']  # Features (email content)\n",
    "y = df_cleaned['label']  # Labels (spam or not spam)\n",
    "\n",
    "# Vectorize the text data if not already done\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit features to manage RAM usage\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature importance (optional, if interested in interpreting the model)\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_indices = importances.argsort()[-10:][::-1]\n",
    "print(\"\\nTop 10 Features:\")\n",
    "for index in top_indices:\n",
    "    print(f\"{feature_names[index]}: {importances[index]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0115d-f488-4057-bdae-0f1a6fa46d01",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c32d7b8-c7a9-4ba8-bd8e-72496e5787e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dani Alex Parayil\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:150: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Dani Alex Parayil\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 227, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.88\n",
      "\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.87      8029\n",
      "           1       0.85      0.95      0.89      8466\n",
      "\n",
      "    accuracy                           0.88     16495\n",
      "   macro avg       0.89      0.88      0.88     16495\n",
      "weighted avg       0.89      0.88      0.88     16495\n",
      "\n",
      "\n",
      "KNN Confusion Matrix:\n",
      "[[6574 1455]\n",
      " [ 449 8017]]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Scale the TF-IDF vectorized data for KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Scale the vectorized data\n",
    "scaler = StandardScaler()  # Scaling for dense data (TF-IDF converted to array earlier)\n",
    "X_train_scaled = scaler.fit_transform(X_train_cleaned)\n",
    "X_test_scaled = scaler.transform(X_test_cleaned)\n",
    "\n",
    "# Step 5: Train a KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, metric='euclidean')  # Choose an appropriate K value\n",
    "knn_model.fit(X_train_scaled, y_train_cleaned)\n",
    "\n",
    "# Step 6: Predict and evaluate\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Compute accuracy and classification report for KNN\n",
    "accuracy_knn = accuracy_score(y_test_cleaned, y_pred_knn)\n",
    "classification_report_knn = classification_report(y_test_cleaned, y_pred_knn)\n",
    "confusion_matrix_knn = confusion_matrix(y_test_cleaned, y_pred_knn)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Accuracy: {accuracy_knn:.2f}\")\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report_knn)\n",
    "print(\"\\nKNN Confusion Matrix:\")\n",
    "print(confusion_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d3f38-138d-45e8-9735-dc05ab1397c8",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eafb4f57-a95d-4020-8306-baddde4fad7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dani Alex Parayil\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1650/1650 - 15s - 9ms/step - accuracy: 0.9649 - loss: 0.1001 - val_accuracy: 0.9842 - val_loss: 0.0471\n",
      "Epoch 2/10\n",
      "1650/1650 - 13s - 8ms/step - accuracy: 0.9908 - loss: 0.0270 - val_accuracy: 0.9849 - val_loss: 0.0542\n",
      "Epoch 3/10\n",
      "1650/1650 - 14s - 8ms/step - accuracy: 0.9960 - loss: 0.0128 - val_accuracy: 0.9845 - val_loss: 0.0603\n",
      "Epoch 4/10\n",
      "1650/1650 - 15s - 9ms/step - accuracy: 0.9965 - loss: 0.0107 - val_accuracy: 0.9845 - val_loss: 0.0696\n",
      "Epoch 5/10\n",
      "1650/1650 - 14s - 8ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9848 - val_loss: 0.0876\n",
      "Epoch 6/10\n",
      "1650/1650 - 9s - 5ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9852 - val_loss: 0.0807\n",
      "Epoch 7/10\n",
      "1650/1650 - 8s - 5ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.9834 - val_loss: 0.0920\n",
      "Epoch 8/10\n",
      "1650/1650 - 8s - 5ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.9838 - val_loss: 0.1036\n",
      "Epoch 9/10\n",
      "1650/1650 - 8s - 5ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9848 - val_loss: 0.1082\n",
      "Epoch 10/10\n",
      "1650/1650 - 9s - 5ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9866 - val_loss: 0.1235\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Neural Network Accuracy: 0.99\n",
      "\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      8029\n",
      "           1       0.99      0.99      0.99      8466\n",
      "\n",
      "    accuracy                           0.99     16495\n",
      "   macro avg       0.99      0.99      0.99     16495\n",
      "weighted avg       0.99      0.99      0.99     16495\n",
      "\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "[[7914  115]\n",
      " [ 121 8345]]\n"
     ]
    }
   ],
   "source": [
    "#Installing TensorFlow\n",
    "#!pip install tensorflow\n",
    "\n",
    "# Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the Neural Network architecture\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Input layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(64, activation='relu'),  # Hidden layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                 loss='binary_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train_cleaned, \n",
    "    validation_split=0.2,  # Use 20% of the training data for validation\n",
    "    epochs=10,  # Number of training epochs (can be tuned)\n",
    "    batch_size=32,  # Batch size (can be tuned)\n",
    "    verbose=2  # Print training progress\n",
    ")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nn_prob = nn_model.predict(X_test_scaled)\n",
    "y_pred_nn = (y_pred_nn_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nn = accuracy_score(y_test_cleaned, y_pred_nn)\n",
    "classification_report_nn = classification_report(y_test_cleaned, y_pred_nn)\n",
    "confusion_matrix_nn = confusion_matrix(y_test_cleaned, y_pred_nn)\n",
    "\n",
    "# Print results\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn:.2f}\")\n",
    "print(\"\\nNeural Network Classification Report:\")\n",
    "print(classification_report_nn)\n",
    "print(\"\\nNeural Network Confusion Matrix:\")\n",
    "print(confusion_matrix_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d3d8f-e483-4e45-ae72-3837de3c0ee4",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "*The notebook implements multiple machine learning models to classify emails as spam or not spam. Key steps include data preprocessing, model training, evaluation, and reporting results for Logistic Regression, Naive Bayes, SVM, Random Forest, KNN, and a Neural Network.*\n",
    "\n",
    "1. Data Cleaning and Preprocessing\n",
    "Anomaly Removal: Anomalous rows with very low TF-IDF scores (rows with negligible textual data) are identified and removed.\n",
    "This step is appropriate since such data likely doesn't contribute meaningfully to model training.\n",
    "Text Preprocessing: Tokenization, removal of punctuation, stopwords, and lemmatization are applied to the subject and body columns.\n",
    "The cleaned subject and body are combined into a single combined_text column. This ensures the text is clean, normalized, and ready for vectorization.\n",
    "    \n",
    "2. TF-IDF Vectorization\n",
    "Purpose: Converts combined_text into numerical features using the top 5000 most frequent terms.\n",
    "Implementation: Features are extracted using TfidfVectorizer and converted to dense arrays. Data is split into training and test sets (X_train, X_test, y_train, y_test).\n",
    "Assessment: Appropriate for text data; the choice of 5000 features strikes a balance between feature richness and computational efficiency.\n",
    "3. Logistic Regression\n",
    "Implementation: Trains a Logistic Regression model with the cleaned data and evaluates accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "Achieves high accuracy (~98%).\n",
    "Assessment: A good baseline model for binary classification. Results suggest its handling the data well.\n",
    "4. Naive Bayes\n",
    "Implementation:\n",
    "A MultinomialNB model is trained on the same vectorized data and evaluated.\n",
    "Achieves accuracy slightly lower than Logistic Regression.\n",
    "Assessment: Correct choice for text classification. Performance may slightly lag behind Logistic Regression due to differences in underlying assumptions.\n",
    "5. SVM (Support Vector Machine)\n",
    "Implementation:\n",
    "Uses an SVM with a linear kernel for classification.\n",
    "Outputs accuracy, classification report, and confusion matrix.\n",
    "Assessment: Appropriate for high-dimensional text data like TF-IDF vectors. Results depend on hyperparameters, but linear kernel is a reasonable starting point.\n",
    "6. Random Forest\n",
    "Implementation:\n",
    "Trains a RandomForestClassifier on the vectorized data.\n",
    "Outputs feature importance, accuracy, and other evaluation metrics.\n",
    "Assessment:\n",
    "Random Forest may not excel in text data compared to tree ensembles like Gradient Boosting (e.g., XGBoost).\n",
    "Feature importance from the model can be insightful for understanding influential words.\n",
    "7. K-Nearest Neighbors (KNN)\n",
    "Feature Scaling:\n",
    "Applies StandardScaler to the TF-IDF vectors (critical for KNN since it relies on distance metrics).\n",
    "Implementation:\n",
    "Trains a KNN model with n_neighbors=5 and evaluates it.\n",
    "Assessment:\n",
    "Feature scaling is correctly applied. However, KNN may struggle with large, sparse datasets due to computational inefficiency.\n",
    "8. Neural Network\n",
    "Architecture:\n",
    "Input layer: Size matches the number of TF-IDF features.\n",
    "Hidden layers: Two dense layers (128 and 64 neurons) with ReLU activation and dropout for regularization.\n",
    "Output layer: A single neuron with sigmoid activation for binary classification.\n",
    "Implementation:\n",
    "Trains the model for 10 epochs with a batch size of 32.\n",
    "Outputs accuracy, classification report, and confusion matrix.\n",
    "Assessment:\n",
    "Well-designed for binary classification. Consider adding early stopping to prevent overfitting.\n",
    "Strengths\n",
    "Comprehensive pipeline covering multiple models.\n",
    "Proper preprocessing and feature scaling where applicable.\n",
    "Clear evaluation with accuracy, precision, recall, F1-score, and confusion matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e1507-bc04-4fce-9de5-7423409b501c",
   "metadata": {},
   "source": [
    "# Areas for Improvement\n",
    "\n",
    "1. Dimensionality Reduction: For models like KNN and Random Forest, consider applying dimensionality reduction (e.g., PCA or Truncated SVD) to the TF-IDF vectors to reduce computational complexity.\n",
    "2. Hyperparameter Tuning: Use grid search or cross-validation to optimize parameters for SVM, KNN, Random Forest, and Neural Networks.\n",
    "3. Model Comparison: Summarize all model results (accuracy, F1-score, etc.) in a table for easier comparison.\n",
    "4. Neural Network Regularization: Add techniques like early stopping or L2 regularization to improve generalization.\n",
    "5. Explainability: Include insights from feature importance (Random Forest) or permutation importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
